import util

from state import State
from node  import Node


class Frontier(object):
    '''
    Frontier class implement a search frontier using a
    PriorityQueue for ordering the nodes and a set for
    constant-time checks of states in frontier.

    OBSERVATION: it receives as input a function `f` that
    itself receives a node and returns the priority for
    the given node. Check util.PriorityQueueWithFunction for
    more details.
    '''

    def __init__(self, f):
        self._queue = util.PriorityQueueWithFunction(f)
        self._set = set()

    def __contains__(self, node):
        ''' Return true if `node.state` is in the frontier. '''
        return node.state in self._set

    def __len__(self):
        ''' Return the number of nodes in frontier. '''
        assert(len(self._queue) == len(self._set))
        return len(self._queue)

    def is_empty(self):
        ''' Return true if frontier is empty. '''
        return self._queue.isEmpty()

    def push(self, node):
        ''' Push `node` to frontier. '''
        self._queue.push(node)
        self._set.add(node.state)

    def pop(self):
        ''' Pop `node` from frontier. '''
        node = self._queue.pop()
        self._set.remove(node.state)
        return node

    def __str__(self):
        ''' Return string representation of frontier. '''
        return str(self._queue)


class ProgressionPlanning(object):
    '''
    ProgressionPlanning class implements all necessary components
    for implicitly generating the state space in a forward way (i.e., by progression).self
    '''

    def __init__(self, domain, problem):
        self._problem = problem
        self._all_actions = problem.ground_all_actions(domain)

    @property
    def problem(self):
        return self._problem

    @property
    def actions(self):
        return self._all_actions

    def applicable(self, state):
        ''' Return a list of applicable actions in a given `state`. '''
        ' YOUR CODE HERE '
        actions = self.actions
        for action in actions:
            if len(state.intersect(action.precond)) != len(action.precond):
                actions.remove(action)
        return actions
        
    def successor(self, state, action):
        ''' Return the sucessor state generated by executing `action` in `state`. '''
        ' YOUR CODE HERE '
        return state.difference(action.neg_effect).union(action.pos_effect)

    def goal_test(self, state):
        ''' Return true if `state` is a goal state. '''
        ' YOUR CODE HERE '
        return str(state) == str(State(self.problem.goal))

    def solve(self, W, heuristics):
        '''
        Implement best-first graph-search WA*. It receives `W` the weight of WA*
        and `heuristics` a function that receives a state s and the planning object (ie., self)
        and returns h(s). Check heuristics.py for more information.

        If problem has solution, return a triple (plan, num_explored, num_generated) where:
         - `plan` is a sequence of actions;
         - `num_explored` is the number of states explored; and
         - `num_generated` is the nubmer of states generated.
        Otherwise, it should return None.

        OBSERVATION: a state is 'explored' when it is removed from the frontier and
        a state is 'generated' when it is the successor state generated by an action
        regardless whether or not it is in the explored set or already in the frontier.
        '''
        plan = []
        num_explored = 0
        num_generated = 0
        ' YOUR CODE HERE '
        start = State(self.problem.init)
        start = Node(start, None, None, 0, W*heuristics(start, self))
        visited = {}
        priority_queue = util.PriorityQueue()

        visited[start.state] = start.h
        priority_queue.push( start, start.h )

        while not priority_queue.isEmpty():
            node = priority_queue.pop()
            state = node.state
            num_explored += 1

            if self.goal_test(state):
                break
            
            for action in self.applicable(state):
                new_state = self.successor(state, action)
                num_generated += 1
                new_state = Node(new_state, action, node, node.g + 1, W*heuristics(new_state, self))

                if new_state.state not in visited:
                    visited[new_state.state] = new_state.g
                    priority_queue.push(new_state, new_state.g + new_state.h)

                elif not new_state == start and new_state.g < visited[new_state.state]:
                    visited[new_state.state] = new_state.g
                    priority_queue.update(new_state, new_state.g + new_state.h)
                    

        plan = node.path()
        return (plan, num_explored, num_generated)

# def aStarSearch(problem, heuristic=nullHeuristic):
#     """Search the node that has the lowest combined cost and heuristic first."""
#     "*** YOUR CODE HERE ***"
#     start = problem.getStartState()
#     visited = list()
#     priority_queue = util.PriorityQueue()
#     g_cost = {}

#     visited.append(start)
#     g_cost[start[0]] = 0
#     priority_queue.push((start, []), heuristic(start, problem))

#     while not priority_queue.isEmpty():
#         (state, path) = priority_queue.pop()

#         if problem.isGoalState(state):
#             return path

#         for (next_state, action, stepCost) in problem.getSuccessors(state):
#             new_path = path + [action]
#             cost = problem.getCostOfActions(new_path) + heuristic(next_state, problem)

#             if next_state not in visited:
#                 visited.append(next_state)
#                 g_cost[next_state[0]] = cost
#                 priority_queue.push((next_state, new_path), cost)

#             elif next_state != start and g_cost[next_state[0]] > cost:
#                 g_cost[next_state[0]] = cost
#                 priority_queue.update((next_state, new_path), cost)
